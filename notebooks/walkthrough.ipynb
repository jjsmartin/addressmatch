{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f85a76c",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "\n",
    "Take some **fictional** name / address data, which we imagine has come from different sources and therefore isn't always the same, and figure out which ones refer to the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09455773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/address_deduplication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947ee36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from normalisation import (\n",
    "    normalise_names, \n",
    "    normalise_addresses, \n",
    "    split_address\n",
    ")\n",
    "from helpers import (\n",
    "    save_all_normalised,\n",
    "    read_normalised,\n",
    "    deterministic_row_id\n",
    ")\n",
    "from deduplication import (\n",
    "    get_cosine_similarity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c08529",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data'\n",
    "INPUT_FOLDER = f'{DATA_FOLDER}/input'\n",
    "NORMALISED_FOLDER = f'{DATA_FOLDER}/normalised'\n",
    "OUTPUT_FOLDER = f'{DATA_FOLDER}/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7f59d",
   "metadata": {},
   "source": [
    "## Load some (fictional data)\n",
    "\n",
    "Small amount of LLM-generated names and addresses, covering two postcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749eb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = pd.read_csv(f'{INPUT_FOLDER}/restaurants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add a unique identifier for each restaurant\n",
    "restaurants['id'] = restaurants.apply(deterministic_row_id, axis=1)\n",
    "\n",
    "# make sure the id in the first column\n",
    "restaurants.insert(0, 'id', restaurants.pop('id'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7491057",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f449b9f9",
   "metadata": {},
   "source": [
    "## Normalise the data\n",
    "\n",
    "Consistent capitalisation, split out postcode etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = split_address(restaurants['address'])  \n",
    "\n",
    "restaurants = (\n",
    "    restaurants\n",
    "      .assign(\n",
    "          name = lambda df: normalise_names(df.name),\n",
    "          address = normalise_addresses(split['address_no_postcode']),\n",
    "        )\n",
    "      .join(split['postcode'])\n",
    "      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e787c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll group by this when doing the deduplication, so we don't have to \n",
    "# compare every pair of restaurants.\n",
    "restaurants['outcode'] = restaurants['postcode'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABBREVIATIONS = {\n",
    "    'St': 'Street',\n",
    "    'Rd': 'Road',\n",
    "    'Ave': 'Avenue',\n",
    "    'Dr': 'Drive',\n",
    "    'Pl': 'Place',\n",
    "    'Ln': 'Lane',\n",
    "    'Sq': 'Square',\n",
    "    'Terr': 'Terrace',\n",
    "}\n",
    "\n",
    "# replace common abbreviations in the address\n",
    "restaurants['address'] = (\n",
    "    restaurants['address']\n",
    "      .replace(ABBREVIATIONS, regex=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f797802",
   "metadata": {},
   "source": [
    "## Save the normalized data\n",
    "\n",
    "For each group being compared (in this case, defined by outcode), save the normalised data as a csv.\n",
    "\n",
    "From now on, we'll work with one group at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a21b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all_normalised(restaurants, NORMALISED_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58598fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = read_normalised('SW4', NORMALISED_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb400a7",
   "metadata": {},
   "source": [
    "## Pairwise similarity\n",
    "\n",
    "Within each postcode, compare all pairs and get at similarity score in the 0-1 range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a624e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all pairs of restaurant *names* in the group\n",
    "name_cosine_sim = get_cosine_similarity(group.name)\n",
    "address_cosine_sim = get_cosine_similarity(group.address)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8270a1a7",
   "metadata": {},
   "source": [
    "## Graph\n",
    "\n",
    "Create a graph where the nodes are the locations and edges are the similarity scores. Remove edges where similarity is beneath some threshold, then find connected components - which we take to be multiple references to a single location.\n",
    "\n",
    "(This is also a convenient step to manually add or remove pairs, if we happen to know certain locations are or are not the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6175f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# create a graph from the cosine similarity matrices\n",
    "G = nx.Graph()\n",
    "\n",
    "# add edges for pairs of restaurants where both name and address cosine similarity are above a threshold\n",
    "name_threshold = 0.1\n",
    "address_threshold = 0.1\n",
    "\n",
    "# number of restaurants in the group\n",
    "n = group.shape[0]\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        if name_cosine_sim[i, j] >= name_threshold and address_cosine_sim[i, j] >= address_threshold:\n",
    "            G.add_edge(group.iloc[i]['id'], group.iloc[j]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the graph -- just for visualisation (with more than a few nodes it's an illegible hairball)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "pos = nx.spring_layout(G)  \n",
    "nx.draw_networkx_nodes(G, pos, node_size=500)\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos, font_size=10)\n",
    "plt.title('Cosine Similarity Graph for Restaurants in SW4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d3e4d",
   "metadata": {},
   "source": [
    "## Manual changes\n",
    "\n",
    "The easiest way to link two restarurants that aren't being matched is to add an edge at this point. We can also remove edges if things are being matched that shouldn't be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these nodes are connected\n",
    "node_a = 'e97ca3f4e4ee26f55b4f1e9e58ca0182'\n",
    "node_b = '2d29b645a21b5a5d9e1809e8c2e48274'\n",
    "node_c = 'b6413c2b889bf7f4df0255df4dddfb43'\n",
    "node_d = 'b4941ace111cbd25bc01342bfbbb1103'\n",
    "\n",
    "# add an edge between the two nodes if they are not already connected\n",
    "G.add_edge(node_a, node_b)\n",
    "G.add_edge(node_b, node_c)\n",
    "G.add_edge(node_c, node_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f706e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO wrap in a function that takes tuples of node IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81601153",
   "metadata": {},
   "source": [
    "## Identify duplicates\n",
    "\n",
    "We'll say that connected components in our graph are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ee0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = list(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a694ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the connected components to a lookup dictionary, where the key is the first restaurant id in the component and the value is a list of all restaurant ids in that component (including the key)\n",
    "def connected_components_to_lookup(components):\n",
    "    lookup = {}\n",
    "    for component in components:\n",
    "        first_id = next(iter(component))  # get the first id in the component\n",
    "        lookup[first_id] = list(component)  # convert the set to a list\n",
    "    return lookup\n",
    "\n",
    "lookup = connected_components_to_lookup(connected_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a323be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new group ID column in the group DataFrame\n",
    "group['group_id'] = group['id'].map(lambda x: next((k for k, v in lookup.items() if x in v), x))\n",
    "\n",
    "# make sure the id in the first column\n",
    "group.insert(0, 'group_id', group.pop('group_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by the group id so we can see the groups together\n",
    "group = group.sort_values(by='group_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426a900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO wrap in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO main.py that runs the whole process from the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c393ae",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c05d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_id, group_df in group.groupby('group_id'):\n",
    "    print(f'Group ID: {group_id}')\n",
    "    display(group_df[['id', 'name', 'address', 'postcode']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ef0538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf4e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
